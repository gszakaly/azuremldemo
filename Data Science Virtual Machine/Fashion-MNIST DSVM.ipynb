{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a simple image classification example using a small convolutional neural network, the Keras deep learning package, and the Fashion-MNIST data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fashion-MNIST data set can be loaded directly from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, ax):\n",
    "    ax.imshow(img, cmap='Greys')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST contains 28x28 greyscale images of cloting articles belonging to 10 categories. The data set contains 60,000 training and 10,000 test images. The data set was created by Zalandor Research as a drop-in replacement for the popular MNIST dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = 2\n",
    "column_count = 10\n",
    "\n",
    "fig, ax = plt.subplots(row_count, column_count, figsize=(column_count, row_count))\n",
    "\n",
    "for x in range(row_count):\n",
    "    for y in range(column_count):\n",
    "        show_img(x_train_orig[np.random.randint(0, x_train_orig.shape[0] - 1)], ax[x, y])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-prcess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the images to the format expected by Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_orig.reshape(x_train_orig.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test_orig.reshape(x_test_orig.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_orig, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_orig, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up training, 5% or the training and 10% of the test images are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = np.random.binomial(1, .05, y_train.shape[0]).astype('bool')\n",
    "mask_test = np.random.binomial(1, .1, y_test.shape[0]).astype('bool')\n",
    "\n",
    "x_train = x_train[mask_train]\n",
    "x_test = x_test[mask_test]\n",
    "\n",
    "y_train = y_train[mask_train]\n",
    "y_test = y_test[mask_test]\n",
    "\n",
    "print('Number of training images: {}'.format(x_train.shape[0]))\n",
    "print('Number of test images:     {}'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simple convolutional neural network consisting of three convolutional layers with progressively smaller image size and increasing depth and one fully connected layer. The softmax activation ensures, that the 10 output values, interpreted as the probability, that the image belongs to that category, are all between 0.0 and 1.0, and their sum is always 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential();\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), strides=2, padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), strides=2, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network over 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss Curves\n",
    "ax[0].plot(train_hist.history['loss'],'r',linewidth=3.0)\n",
    "ax[0].plot(train_hist.history['val_loss'],'b',linewidth=3.0)\n",
    "ax[0].grid(True, axis = 'y')\n",
    "ax[0].legend(['Training loss', 'Validation Loss'])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Loss Curves')\n",
    "\n",
    "# Accuracy Curves\n",
    "ax[1].plot(train_hist.history['categorical_accuracy'],'r',linewidth=3.0)\n",
    "ax[1].plot(train_hist.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
    "ax[1].grid(True, axis = 'y')\n",
    "ax[1].legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Accuracy Curves')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of the loss function (the value that the training tries to minimize) and the accuracy during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "y_test_value = np.argmax(y_test, axis=1)\n",
    "y_test_pred_value = np.argmax(y_test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test_value, y_test_pred_value)\n",
    "plt.imshow(np.log(confusion_matrix), cmap='Blues')\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the distribution of the observations in terms of true category (rows) and predicted categories (columns). The observations on the diagonal are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', metrics.accuracy_score(y_test_value, y_test_pred_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
